Evaluation Report
=================

Test CSV: dataset\processed\test.csv
Model: models\final_model.h5

Evaluated samples: 2342
Test Accuracy: 0.607173
Macro AUC (ovr): 0.572773

Classification Report:
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000       311
           1     0.0000    0.0000    0.0000       609
           2     0.6072    1.0000    0.7556      1422

    accuracy                         0.6072      2342
   macro avg     0.2024    0.3333    0.2519      2342
weighted avg     0.3687    0.6072    0.4588      2342

Confusion Matrix:
[[   0    0  311]
 [   0    0  609]
 [   0    0 1422]]